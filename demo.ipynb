{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Poem Generation\n",
    "\n",
    "Jupyter Notebook for build a Multi-Agent poem generator using Langchain & LangGraph.\n",
    "\n",
    "Prerequisites:\n",
    "\n",
    "1. Python (v3.8.1 or above)\n",
    "2. Ollama (v0.3.9 or above)\n",
    "    1. Moondream 2 model\n",
    "    2. Gemma 2: 2B model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph langsmith\n",
    "%pip install -U langchain_ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Multi-Agent Poem Generation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "Here, we define two helper functions for creating LLM agents and LangChain nodes that can be added to the graph and utilize message history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "def create_agent(llm, system_prompt):\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [HumanMessage(content=result.content, name=name)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the graph\n",
    "One of the central concepts of LangGraph is state. Each graph execution creates a state that is passed between nodes in the graph as they execute, and each node updates this internal state with its return value after it executes. \n",
    "\n",
    "Here, we create a simple State class that defines how messages between agents are stored within the State. We then create a StateGraph object, which is the graph in which all agents are added to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can create the agents and provide each with distinct prompts, ensuring that each agent exhibits unique behaviors within the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_prompt = \"\"\"You are the Analyst Agent, an expert in visual analysis. \n",
    "Your task is to examine images in detail and provide a comprehensive description \n",
    "of what you see. Describe the scene as thoroughly as possible\"\"\"\n",
    "\n",
    "creative_prompt = \"\"\"You are the Creator Agent, a talented poet and creative writer. \n",
    "Your task is to take detailed descriptions of images provided by the Analyst Agent \n",
    "and craft a funny poem based on the imagery and emotions conveyed. \"\"\"\n",
    "\n",
    "analysis_llm = ChatOllama(model=\"moondream\")\n",
    "creative_llm = ChatOllama(model=\"gemma2:2b\")\n",
    "\n",
    "analysis_agent = create_agent(analysis_llm, creative_prompt)\n",
    "creative_agent = create_agent(creative_llm, creative_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the agents, we can then create nodes from them, and define how they are connecting up to each other within the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "analysis_node = functools.partial(\n",
    "    agent_node, agent=analysis_agent, name=\"Analysis Agent\"\n",
    ")\n",
    "creative_node = functools.partial(\n",
    "    agent_node, agent=creative_agent, name=\"Creative Agent\"\n",
    ")\n",
    "\n",
    "graph_builder.add_node(\"Analysis Agent\", analysis_node)\n",
    "graph_builder.add_node(\"Creative Agent\", creative_node)\n",
    "\n",
    "graph_builder.add_edge(START, \"Analysis Agent\")\n",
    "graph_builder.add_edge(\"Analysis Agent\", \"Creative Agent\")\n",
    "graph_builder.add_edge(\"Creative Agent\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing in multi-modal data\n",
    "LangGraph supports Multi-Modal LLMs, allowing us to create an initial message for the graph that includes both images and text. To achieve this, we first convert the image into a Base64-encoded binary string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "image_file = \"hedgehog.jpg\"\n",
    "image_path = f\"images/{image_file}\"\n",
    "\n",
    "with open(image_path, \"rb\") as file:\n",
    "    encoded_string = base64.b64encode(file.read()).decode(\"utf-8\")\n",
    "\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_string}\"},\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can run the graph with our message as the initial input using the `stream()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Analysis Agent: \n",
      "The image features a small white and brown hedgehog sitting in the grass. The hedgehog is facing towards the camera, giving us a close-up view of its adorable appearance. It appears to be enjoying itself as it lounges on the green grassy field.\n",
      "---\n",
      "Creative Agent: A tiny prince, with quills so neat, \n",
      "In emerald fields, a joyful treat!\n",
      "He yawns, he smiles, a prickly grin,\n",
      "His furry face, where mischief spins.\n",
      "\n",
      "His nose is twitching, keen and bright,\n",
      "For juicy worms, a pure delight! \n",
      "A fluffy crown upon his head,\n",
      "Of softest fur, of purest dread.\n",
      "\n",
      "He dreams of berries, plump and red,\n",
      "And feasts in secret, in the grass he's tread.\n",
      "Oh, humble hedgehogs, small and bold,\n",
      "With stories to tell, yet to be told! \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream({\"messages\": [message]}):\n",
    "    for value in event.values():\n",
    "        message = value[\"messages\"][-1]\n",
    "        print(f\"---\\n{message.name}: {message.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
